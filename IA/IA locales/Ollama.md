# Modelos Ollama
https://ollama.ai/library

# Instalar Llama3
```Bash
ollama run llama3:8b
```
![[Pasted image 20240918120302.png]]


```Bash
Ollama pull Llama3
```

# Listar modelos IA
```Bash
ollama llist
```
![[Pasted image 20240918120322.png]]
# Ejecutar modelo IA
```Bash
ollama run Llama3
```
![[Pasted image 20240513092552.png]]
# Lugar donde se ejecuta nuestro modelo
```Bash
ollama serve
```
![[Pasted image 20240918120340.png]]

El puerto por el que corre este lenguaje es 11434
![[Pasted image 20240513092633.png]]


